{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual explanations with one-hot encoded categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real world machine learning applications often handle data with categorical variables. Explanation methods which rely on perturbations of the input features need to make sure those perturbations are meaningful and capture the underlying structure of the data. This becomes tricky for categorical features. For instance random perturbations across possible categories or enforcing a ranking between categories based on frequency of occurrence in the training data do not capture this structure. Our method captures the relation between categories of a variable numerically through the context given by the other features in the data and/or the predictions made by the model. First it captures the pairwise distances between categories and then applies multi-dimensional scaling. More details about the method can be found in the [documentation](https://docs.seldon.io/projects/alibi/en/stable/methods/CFProto.html). The example notebook illustrates this approach on the *adult* dataset, which contains a mixture of categorical and numerical features used to predict whether a person's income is above or below $50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "    \n",
    "To enable support for CounterfactualProto, you may need to run\n",
    "    \n",
    "```bash\n",
    "pip install alibi[tensorflow]\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.12.1\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import time\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.explainers import CounterfactualProto\n",
    "from alibi.utils import ohe_to_ord, ord_to_ohe\n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_adult` function returns a `Bunch` object containing the features, the targets, the feature names and a mapping of the categories in each categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map_tmp = adult.category_map\n",
    "target_names = adult.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define shuffled training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "X = data_perm[:,:-1]\n",
    "y = data_perm[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 30000\n",
    "y_train, y_test = y[:idx], y[idx+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganize data so categorical features come first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X[:, 1:8], X[:, 11], X[:, 0], X[:, 8:11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `feature_names` and `category_map` as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country', 'Age', 'Capital Gain', 'Capital Loss', 'Hours per week']\n"
     ]
    }
   ],
   "source": [
    "feature_names = feature_names[1:8] + feature_names[11:12] + feature_names[0:1] + feature_names[8:11]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {}\n",
    "for i, (_, v) in enumerate(category_map_tmp.items()):\n",
    "    category_map[i] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with as keys the categorical columns and values the number of categories for each variable in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 1: 7, 2: 4, 3: 9, 4: 6, 5: 5, 6: 2, 7: 11}\n"
     ]
    }
   ],
   "source": [
    "cat_vars_ord = {}\n",
    "n_categories = len(list(category_map.keys()))\n",
    "for i in range(n_categories):\n",
    "    cat_vars_ord[i] = len(np.unique(X[:, i]))\n",
    "print(cat_vars_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will apply one-hot encoding (OHE) on the categorical variables, we convert `cat_vars_ord` from the ordinal to OHE format. `alibi.utils.mapping` contains utility functions to do this. The keys in `cat_vars_ohe` now represent the first column index for each one-hot encoded categorical variable. This dictionary will later be used in the counterfactual explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 9: 7, 16: 4, 20: 9, 29: 6, 35: 5, 40: 2, 42: 11}\n"
     ]
    }
   ],
   "source": [
    "cat_vars_ohe = ord_to_ohe(X, cat_vars_ord)[1]\n",
    "print(cat_vars_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale numerical features between -1 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X[:, -4:].astype(np.float32, copy=False)\n",
    "xmin, xmax = X_num.min(axis=0), X_num.max(axis=0)\n",
    "rng = (-1., 1.)\n",
    "X_num_scaled = (X_num - xmin) / (xmax - xmin) * (rng[1] - rng[0]) + rng[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply OHE to categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    }
   ],
   "source": [
    "X_cat = X[:, :-4].copy()\n",
    "ohe = OneHotEncoder(categories='auto', sparse=False).fit(X_cat)\n",
    "X_cat_ohe = ohe.transform(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine numerical and categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 57) (2560, 57)\n"
     ]
    }
   ],
   "source": [
    "X = np.c_[X_cat_ohe, X_num_scaled].astype(np.float32, copy=False)\n",
    "X_train, X_test = X[:idx, :], X[idx+1:, :]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select one of the below classifiers.\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(min_child_weight=0.5, max_depth=3, gamma=0.2)\n",
    "# clf = LogisticRegression(C=10)\n",
    "# clf = DecisionTreeClassifier(max_depth=10, min_samples_split=5)\n",
    "#clf = RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=50)\n",
    "\n",
    "# Fit the classifier.\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.718\n"
     ]
    }
   ],
   "source": [
    "def predict_fn(X):\n",
    "    # The predict_proba method of the pipeline returns an array of shape (n_samples, 2)\n",
    "    # Return both columns as the CounterfactualProto explainer expects a probability for each class\n",
    "    pred_proba = clf.predict_proba(X)\n",
    "    return np.hstack([1 - pred_proba[:, 1].reshape(-1, 1), pred_proba[:, 1].reshape(-1, 1)])\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "acc = f1_score(y_true=y_test, y_pred=predict_fn(X_test).argmax(axis=1))\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test[0].reshape((1,) + X_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize counterfactual parameters. The feature perturbations are applied in the numerical feature space, after transforming the categorical variables to numerical features. As a result, the dimensionality and values of `feature_range` are defined in the numerical space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X.shape\n",
    "beta = .01\n",
    "c_init = 1.\n",
    "c_steps = 5\n",
    "max_iterations = 500\n",
    "rng = (-1., 1.)  # scale features between -1 and 1\n",
    "rng_shape = (1,) + data.shape[1:]\n",
    "feature_range = ((np.ones(rng_shape) * rng[0]).astype(np.float32), \n",
    "                 (np.ones(rng_shape) * rng[1]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit explainer. `d_type` refers to the distance metric used to convert the categorical to numerical values. Valid options are `abdm`, `mvdm` and `abdm-mvdm`. `abdm` infers the distance between categories of the same variable from the context provided by the other variables. This requires binning of the numerical features as well. `mvdm` computes the distance using the model predictions, and `abdm-mvdm` combines both methods. More info on both distance measures can be found in the [documentation](https://docs.seldon.io/projects/alibi/en/stable/methods/CFProto.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to more clearly describe explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_instance(X, explanation, eps=1e-2):\n",
    "    print('Original instance: {}  -- proba: {}'.format(target_names[explanation.orig_class],\n",
    "                                                       explanation.orig_proba[0]))\n",
    "    print('Counterfactual instance: {}  -- proba: {}'.format(target_names[explanation.cf['class']],\n",
    "                                                             explanation.cf['proba'][0]))\n",
    "    print('\\nCounterfactual perturbations...')\n",
    "    print('\\nCategorical:')\n",
    "    X_orig_ord = ohe_to_ord(X, cat_vars_ohe)[0]\n",
    "    X_cf_ord = ohe_to_ord(explanation.cf['X'], cat_vars_ohe)[0]\n",
    "    delta_cat = {}\n",
    "    for i, (_, v) in enumerate(category_map.items()):\n",
    "        cat_orig = v[int(X_orig_ord[0, i])]\n",
    "        cat_cf = v[int(X_cf_ord[0, i])]\n",
    "        if cat_orig != cat_cf:\n",
    "            delta_cat[feature_names[i]] = [cat_orig, cat_cf]\n",
    "    if delta_cat:\n",
    "        for k, v in delta_cat.items():\n",
    "            print('{}: {}  -->   {}'.format(k, v[0], v[1]))\n",
    "    print('\\nNumerical:')\n",
    "    delta_num = X_cf_ord[0, -4:] - X_orig_ord[0, -4:]\n",
    "    n_keys = len(list(cat_vars_ord.keys()))\n",
    "    for i in range(delta_num.shape[0]):\n",
    "        if np.abs(delta_num[i]) > eps:\n",
    "            print('{}: {:.2f}  -->   {:.2f}'.format(feature_names[i+n_keys],\n",
    "                                            X_orig_ord[0,i+n_keys],\n",
    "                                            X_cf_ord[0,i+n_keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.779083   0.22091702]\n",
      "Counterfactual instance: >50K  -- proba: [0.3595787 0.6404213]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: Associates  -->   Bachelors\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By obtaining a higher level of education the income is predicted to be above $50k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "cf = CounterfactualProto(predict_fn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,  # OHE flag\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n"
     ]
    }
   ],
   "source": [
    "cf.fit(X_train, d_type='abdm', disc_perc=[25, 50, 75]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No counterfactual found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: >50K  -- proba: [0.4741686 0.5258314]\n",
      "Counterfactual instance: <=50K  -- proba: [0.6037574  0.39624265]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Marital Status: Never-Married  -->   Married\n",
      "Relationship: Own-child  -->   Husband\n",
      "\n",
      "Numerical:\n",
      "Age: -0.89  -->   -0.10\n",
      "Hours per week: -0.61  -->   -0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: >50K  -- proba: [0.41468304 0.58531696]\n",
      "Counterfactual instance: <=50K  -- proba: [0.55429494 0.44570506]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Marital Status: Never-Married  -->   Married\n",
      "Occupation: Blue-Collar  -->   Sales\n",
      "Relationship: Own-child  -->   Husband\n",
      "\n",
      "Numerical:\n",
      "Age: -0.89  -->   -0.45\n",
      "Hours per week: -0.61  -->   -0.16\n",
      "Original instance: >50K  -- proba: [0.23521066 0.76478934]\n",
      "Counterfactual instance: <=50K  -- proba: [0.6633158 0.3366842]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: High School grad  -->   Bachelors\n",
      "Marital Status: Never-Married  -->   Married\n",
      "Occupation: Blue-Collar  -->   Service\n",
      "Relationship: Own-child  -->   Husband\n",
      "\n",
      "Numerical:\n",
      "Age: -0.89  -->   0.21\n",
      "Hours per week: -0.61  -->   -0.20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Loop through each instance and generate counterfactual\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances:\n\u001b[1;32m---> 13\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Check if a counterfactual was found\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m explanation\u001b[38;5;241m.\u001b[39mcf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\cfproto.py:1355\u001b[0m, in \u001b[0;36mCounterfactualProto.explain\u001b[1;34m(self, X, Y, target_class, k, k_type, threshold, verbose, print_every, log_every)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;66;03m# find best counterfactual\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_attack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1355\u001b[0m best_attack, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_or_kdtree:\n\u001b[0;32m   1360\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_proto\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_proto\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\cfproto.py:1162\u001b[0m, in \u001b[0;36mCounterfactualProto.attack\u001b[1;34m(self, X, Y, target_class, k, k_type, threshold, verbose, print_every, log_every)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mohe:\n\u001b[0;32m   1161\u001b[0m     X_der \u001b[38;5;241m=\u001b[39m ord_to_ohe(X_der, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_vars_ord)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1162\u001b[0m pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_der\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;66;03m# compute attack, total and L1+L2 losses as well as new perturbed instance\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m loss_attack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(pred_proba, Y)\n",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m, in \u001b[0;36mpredict_fn\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_fn\u001b[39m(X):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# The predict_proba method of the pipeline returns an array of shape (n_samples, 2)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Return both columns as the CounterfactualProto explainer expects a probability for each class\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pred_proba[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), pred_proba[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1606\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[1;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1604\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m softmax(raw_predt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[1;32m-> 1606\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mntree_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntree_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;66;03m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_classes_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m), class_probs, np\u001b[38;5;241m.\u001b[39mvstack\n\u001b[0;32m   1616\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1114\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:2293\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2289\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n\u001b[0;32m   2291\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m _ensure_np_dtype(data, data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2292\u001b[0m     _check_call(\n\u001b[1;32m-> 2293\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2295\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_array_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfrom_pystr_to_cstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2302\u001b[0m     )\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred=predict_fn(X_test).argmax(axis=1)\n",
    "instances = X_test[y_pred == 1]\n",
    "\n",
    "import time\n",
    "# List to store counterfactuals\n",
    "counterfactuals = []\n",
    "\n",
    "start_time = time.time()\n",
    "# Loop through each instance and generate counterfactual\n",
    "\n",
    "\n",
    "for instance in instances:\n",
    "    explanation = cf.explain(instance.reshape(1, -1))\n",
    "    # Check if a counterfactual was found\n",
    "    if explanation.cf is not None:\n",
    "        counterfactuals.append(explanation.cf['X'])\n",
    "        describe_instance(X, explanation)\n",
    "    else:\n",
    "        # You can append a placeholder or simply skip\n",
    "        # Here, I'm appending None to indicate no counterfactual was found for this instance\n",
    "        counterfactuals.append(None)\n",
    "        \n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the categorical distance metric\n",
    "\n",
    "Instead of `abdm`, we now use `mvdm` as our distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.70744723 0.29255277]\n",
      "Counterfactual instance: >50K  -- proba: [0.38161737 0.61838263]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: Associates  -->   Bachelors\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "cf.fit(X_train, d_type='mvdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same conclusion hold using a different distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use k-d trees to build prototypes\n",
    "\n",
    "We can also use *k-d trees* to build class prototypes to guide the counterfactual to nearby instances in the counterfactual class as described in [Interpretable Counterfactual Explanations Guided by Prototypes](https://arxiv.org/abs/1907.02584). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_kdtree = True\n",
    "theta = 10.  # weight of prototype loss term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, fit and explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.5211548  0.47884512]\n",
      "Counterfactual instance: >50K  -- proba: [0.49958408 0.500416  ]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "\n",
      "Numerical:\n",
      "Age: -0.53  -->   -0.51\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "X = X_test[7].reshape((1,) + X_test[0].shape)\n",
    "cf = CounterfactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         use_kdtree=use_kdtree,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By slightly increasing the age of the person the income would be predicted to be above $50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an autoencoder to build prototypes\n",
    "\n",
    "Another option is to use an autoencoder to guide the perturbed instance to the counterfactual class. We define and train the autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_model():\n",
    "    # encoder\n",
    "    x_in = Input(shape=(57,))\n",
    "    x = Dense(60, activation='relu')(x_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(15, activation='relu')(x)\n",
    "    encoded = Dense(10, activation=None)(x)\n",
    "    encoder = Model(x_in, encoded)\n",
    "    \n",
    "    # decoder\n",
    "    dec_in = Input(shape=(10,))\n",
    "    x = Dense(15, activation='relu')(dec_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    decoded = Dense(57, activation=None)(x)\n",
    "    decoder = Model(dec_in, decoded)\n",
    "    \n",
    "    # autoencoder = encoder + decoder\n",
    "    x_out = decoder(encoder(x_in))\n",
    "    autoencoder = Model(x_in, x_out)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 57)]              0         \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, 10)                5935      \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, 57)                5982      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,917\n",
      "Trainable params: 11,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 2560 samples\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 2s 51us/sample - loss: 0.0684 - val_loss: 0.0434\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0369 - val_loss: 0.0333\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0300 - val_loss: 0.0283\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0229 - val_loss: 0.0223\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0212 - val_loss: 0.0208\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0200 - val_loss: 0.0197\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 1s 23us/sample - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 1s 24us/sample - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 1s 23us/sample - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 1s 23us/sample - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 1s 23us/sample - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 1s 23us/sample - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 1s 19us/sample - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 1s 20us/sample - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 1s 21us/sample - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 1s 22us/sample - loss: 0.0100 - val_loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d7a524f3d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "ae, enc, dec = ae_model()\n",
    "ae.summary()\n",
    "ae.fit(X_train, X_train, batch_size=128, epochs=100, validation_data=(X_test, X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights for the autoencoder and prototype loss terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = .1  # L1\n",
    "gamma = 10.  # autoencoder\n",
    "theta = .1  # prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, fit and explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both an encoder and k-d trees enabled. Using the encoder for the prototype loss term.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CounterfactualProto(meta={\n",
       "  'name': 'CounterfactualProto',\n",
       "  'type': ['blackbox', 'tensorflow', 'keras'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {\n",
       "              'kappa': 0.0,\n",
       "              'beta': 0.1,\n",
       "              'gamma': 10.0,\n",
       "              'theta': 0.1,\n",
       "              'cat_vars': {\n",
       "                            0: 9,\n",
       "                            9: 7,\n",
       "                            16: 4,\n",
       "                            20: 9,\n",
       "                            29: 6,\n",
       "                            35: 5,\n",
       "                            40: 2,\n",
       "                            42: 11}\n",
       "                          ,\n",
       "              'ohe': True,\n",
       "              'use_kdtree': True,\n",
       "              'learning_rate_init': 0.01,\n",
       "              'max_iterations': 500,\n",
       "              'c_init': 1.0,\n",
       "              'c_steps': 5,\n",
       "              'eps': (0.001, 0.001),\n",
       "              'clip': (-1000.0, 1000.0),\n",
       "              'update_num_grad': 1,\n",
       "              'write_dir': None,\n",
       "              'feature_range': (array([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]],\n",
       "      dtype=float32), array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)),\n",
       "              'shape': (1, 57),\n",
       "              'is_model': False,\n",
       "              'is_ae': True,\n",
       "              'is_enc': True,\n",
       "              'enc_or_kdtree': True,\n",
       "              'is_cat': True,\n",
       "              'trustscore_kwargs': None,\n",
       "              'd_type': 'abdm',\n",
       "              'w': None,\n",
       "              'disc_perc': (25, 50, 75),\n",
       "              'standardize_cat_vars': False,\n",
       "              'smooth': 1.0,\n",
       "              'center': True,\n",
       "              'update_feature_range': True}\n",
       "            ,\n",
       "  'version': '0.9.4'}\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "X = X_test[19].reshape((1,) + X_test[0].shape)\n",
    "cf = CounterfactualProto(predict_fn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         enc_model=enc,\n",
    "                         ae_model=ae,\n",
    "                         gamma=gamma,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps,\n",
    "                         use_kdtree = True\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: >50K  -- proba: [0.09381664 0.90618336]\n",
      "Counterfactual instance: <=50K  -- proba: [0.6888168 0.3111832]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "\n",
      "Numerical:\n",
      "Capital Loss: -0.13  -->   -0.18\n",
      "83.16250443458557\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances:\n\u001b[0;32m     13\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 14\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Check if a counterfactual was found\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m explanation\u001b[38;5;241m.\u001b[39mcf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\cfproto.py:1355\u001b[0m, in \u001b[0;36mCounterfactualProto.explain\u001b[1;34m(self, X, Y, target_class, k, k_type, threshold, verbose, print_every, log_every)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;66;03m# find best counterfactual\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_attack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1355\u001b[0m best_attack, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_or_kdtree:\n\u001b[0;32m   1360\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_proto\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_proto\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\cfproto.py:1129\u001b[0m, in \u001b[0;36mCounterfactualProto.attack\u001b[1;34m(self, X, Y, target_class, k, k_type, threshold, verbose, print_every, log_every)\u001b[0m\n\u001b[0;32m   1127\u001b[0m X_der_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(X_der_batch)\n\u001b[0;32m   1128\u001b[0m X_der_batch_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(X_der_batch_s)\n\u001b[1;32m-> 1129\u001b[0m grads_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_der_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_vars_ord\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat_vars_ord\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mgrads_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpert_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m c\n\u001b[0;32m   1131\u001b[0m grads_num_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gradients(X_der_batch_s, Y, cat_vars_ord\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_vars_ord,\n\u001b[0;32m   1132\u001b[0m                                  grads_shape\u001b[38;5;241m=\u001b[39mpert_shape[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m*\u001b[39m c\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\cfproto.py:875\u001b[0m, in \u001b[0;36mCounterfactualProto.get_gradients\u001b[1;34m(self, X, Y, grads_shape, cat_vars_ord)\u001b[0m\n\u001b[0;32m    872\u001b[0m     X_pred \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    873\u001b[0m \u001b[38;5;66;03m# N = gradient batch size; F = nb of features; P = nb of prediction classes; B = instance batch size\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# dL/dP -> BxP\u001b[39;00m\n\u001b[1;32m--> 875\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pred\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# NxP\u001b[39;00m\n\u001b[0;32m    876\u001b[0m preds_pert_pos, preds_pert_neg \u001b[38;5;241m=\u001b[39m perturb(preds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps[\u001b[38;5;241m0\u001b[39m], proba\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# (N*P)xP\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(preds_pert):\n",
      "Cell \u001b[1;32mIn[53], line 4\u001b[0m, in \u001b[0;36mpredict_fn\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_fn\u001b[39m(X):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# The predict_proba method of the pipeline returns an array of shape (n_samples, 2)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Return both columns as the CounterfactualProto explainer expects a probability for each class\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pred_proba[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), pred_proba[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1606\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[1;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1604\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m softmax(raw_predt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[1;32m-> 1606\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mntree_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntree_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;66;03m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_classes_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m), class_probs, np\u001b[38;5;241m.\u001b[39mvstack\n\u001b[0;32m   1616\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1107\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1067\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1073\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict with `X`.  If the model is trained with early stopping, then `best_iteration`\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;124;03m    is used automatically.  For tree models, when data is on GPU, like cupy array or\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;124;03m    cuDF dataframe and `predictor` is not specified, the prediction is run on GPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1107\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m   1108\u001b[0m         iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\n\u001b[0;32m   1109\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster(), ntree_limit, iteration_range\n\u001b[0;32m   1110\u001b[0m         )\n\u001b[0;32m   1111\u001b[0m         iteration_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iteration_range(iteration_range)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\config.py:186\u001b[0m, in \u001b[0;36mconfig_context\u001b[1;34m(**new_config)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     set_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mold_config)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\config.py:108\u001b[0m, in \u001b[0;36mconfig_doc.<locals>.config_doc_decorator.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\xgboost\\config.py:132\u001b[0m, in \u001b[0;36mset_config\u001b[1;34m(**new_config)\u001b[0m\n\u001b[0;32m    130\u001b[0m         not_none[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m    131\u001b[0m config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(not_none)\n\u001b[1;32m--> 132\u001b[0m _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBSetGlobalConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred=predict_fn(X_test).argmax(axis=1)\n",
    "instances = X_test[y_pred == 1]\n",
    "\n",
    "import time\n",
    "# List to store counterfactuals\n",
    "counterfactuals = []\n",
    "\n",
    "\n",
    "# Loop through each instance and generate counterfactual\n",
    "\n",
    "\n",
    "for instance in instances:\n",
    "    start_time = time.time()\n",
    "    explanation = cf.explain(instance.reshape(1, -1))\n",
    "    # Check if a counterfactual was found\n",
    "    if explanation.cf is not None:\n",
    "        counterfactuals.append(explanation.cf['X'])\n",
    "        describe_instance(instance.reshape(1, -1), explanation)\n",
    "    else:\n",
    "        # You can append a placeholder or simply skip\n",
    "        # Here, I'm appending None to indicate no counterfactual was found for this instance\n",
    "        counterfactuals.append(None)\n",
    "    end_time = time.time()\n",
    "# Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from alibi.explainers import CounterfactualRLTabular, CounterfactualRL\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.models.tensorflow import HeAE\n",
    "from alibi.models.tensorflow import Actor, Critic\n",
    "from alibi.models.tensorflow import ADULTEncoder, ADULTDecoder\n",
    "from alibi.explainers.cfrl_base import Callback\n",
    "from alibi.explainers.backends.cfrl_tabular import get_he_preprocessor, get_statistics, \\\n",
    "    get_conditional_vector, apply_category_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CounterfactualRLTabular(predictor=predictor,\n",
    "                                    encoder=heae.encoder,\n",
    "                                    decoder=heae.decoder,\n",
    "                                    latent_dim=LATENT_DIM,\n",
    "                                    encoder_preprocessor=heae_preprocessor,\n",
    "                                    decoder_inv_preprocessor=heae_inv_preprocessor,\n",
    "                                    coeff_sparsity=COEFF_SPARSITY,\n",
    "                                    coeff_consistency=COEFF_CONSISTENCY,\n",
    "                                    category_map=adult.category_map,\n",
    "                                    feature_names=adult.feature_names,\n",
    "                                    ranges=ranges,\n",
    "                                    immutable_features=immutable_features,\n",
    "                                    train_steps=TRAIN_STEPS,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    backend=\"tensorflow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
