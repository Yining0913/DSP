{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae07923",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03317bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "credit = pd.read_csv('../datasets/Credit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d723c14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>checkingstatus1</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>sex</th>\n",
       "      <th>residence</th>\n",
       "      <th>age</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>liable</th>\n",
       "      <th>tele</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;DM0</td>\n",
       "      <td>6</td>\n",
       "      <td>terrible</td>\n",
       "      <td>goods/repair</td>\n",
       "      <td>1169</td>\n",
       "      <td>DM0-100</td>\n",
       "      <td>7+years</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>DM0-200</td>\n",
       "      <td>48</td>\n",
       "      <td>poor</td>\n",
       "      <td>goods/repair</td>\n",
       "      <td>5951</td>\n",
       "      <td>DM0-100</td>\n",
       "      <td>1-7years</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NoAccount</td>\n",
       "      <td>12</td>\n",
       "      <td>terrible</td>\n",
       "      <td>edu</td>\n",
       "      <td>2096</td>\n",
       "      <td>DM0-100</td>\n",
       "      <td>1-7years</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;DM0</td>\n",
       "      <td>42</td>\n",
       "      <td>poor</td>\n",
       "      <td>goods/repair</td>\n",
       "      <td>7882</td>\n",
       "      <td>DM0-100</td>\n",
       "      <td>1-7years</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>forfree</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;DM0</td>\n",
       "      <td>24</td>\n",
       "      <td>poor</td>\n",
       "      <td>newcar</td>\n",
       "      <td>4870</td>\n",
       "      <td>DM0-100</td>\n",
       "      <td>1-7years</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>forfree</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Default checkingstatus1  duration   history       purpose  amount  savings  \\\n",
       "1        0            <DM0         6  terrible  goods/repair    1169  DM0-100   \n",
       "2        1         DM0-200        48      poor  goods/repair    5951  DM0-100   \n",
       "3        0       NoAccount        12  terrible           edu    2096  DM0-100   \n",
       "4        0            <DM0        42      poor  goods/repair    7882  DM0-100   \n",
       "5        1            <DM0        24      poor        newcar    4870  DM0-100   \n",
       "\n",
       "     employ  installment     sex  residence  age  housing  cards  liable tele  \\\n",
       "1   7+years            4    male          4   67      own      2       1  yes   \n",
       "2  1-7years            2  female          2   22      own      1       1   no   \n",
       "3  1-7years            2    male          3   49      own      1       2   no   \n",
       "4  1-7years            2    male          4   45  forfree      1       2   no   \n",
       "5  1-7years            3    male          4   53  forfree      2       2   no   \n",
       "\n",
       "   foreign  \n",
       "1  foreign  \n",
       "2  foreign  \n",
       "3  foreign  \n",
       "4  foreign  \n",
       "5  foreign  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae44bdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>checkingstatus1</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>sex</th>\n",
       "      <th>residence</th>\n",
       "      <th>age</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>liable</th>\n",
       "      <th>tele</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7882</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  checkingstatus1  duration  history  purpose  amount  savings  \\\n",
       "1       0                0         6        2        2    1169        0   \n",
       "2       1                1        48        1        2    5951        0   \n",
       "3       0                3        12        2        1    2096        0   \n",
       "4       0                0        42        1        2    7882        0   \n",
       "5       1                0        24        1        3    4870        0   \n",
       "\n",
       "   employ  installment  sex  residence  age  housing  cards  liable  tele  \\\n",
       "1       2            4    1          4   67        1      2       1     1   \n",
       "2       1            2    0          2   22        1      1       1     0   \n",
       "3       1            2    1          3   49        1      1       2     0   \n",
       "4       1            2    1          4   45        0      1       2     0   \n",
       "5       1            3    1          4   53        0      2       2     0   \n",
       "\n",
       "   foreign  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "5        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "credit_processed = credit.copy()\n",
    "\n",
    "\n",
    "label_encoders = {}  \n",
    "for column in credit_processed.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    credit_processed[column] = le.fit_transform(credit_processed[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "\n",
    "credit_processed = credit_processed.rename(columns={'Default': 'target'})\n",
    "\n",
    "credit_processed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bc21aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>duration</th>\n",
       "      <th>amount</th>\n",
       "      <th>installment</th>\n",
       "      <th>residence</th>\n",
       "      <th>age</th>\n",
       "      <th>cards</th>\n",
       "      <th>liable</th>\n",
       "      <th>checkingstatus1_DM0-200</th>\n",
       "      <th>checkingstatus1_DM200+</th>\n",
       "      <th>...</th>\n",
       "      <th>savings_DM100-1000</th>\n",
       "      <th>savings_DM1000+</th>\n",
       "      <th>employ_1-7years</th>\n",
       "      <th>employ_7+years</th>\n",
       "      <th>employ_unemployed</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>housing_own</th>\n",
       "      <th>housing_rent</th>\n",
       "      <th>tele_yes</th>\n",
       "      <th>foreign_german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  duration  amount  installment  residence   age  cards  liable  \\\n",
       "1     0.0       6.0  1169.0          4.0        4.0  67.0    2.0     1.0   \n",
       "2     1.0      48.0  5951.0          2.0        2.0  22.0    1.0     1.0   \n",
       "3     0.0      12.0  2096.0          2.0        3.0  49.0    1.0     2.0   \n",
       "4     0.0      42.0  7882.0          2.0        4.0  45.0    1.0     2.0   \n",
       "5     1.0      24.0  4870.0          3.0        4.0  53.0    2.0     2.0   \n",
       "\n",
       "   checkingstatus1_DM0-200  checkingstatus1_DM200+  ...  savings_DM100-1000  \\\n",
       "1                      1.0                     0.0  ...                 0.0   \n",
       "2                      0.0                     0.0  ...                 0.0   \n",
       "3                      0.0                     0.0  ...                 0.0   \n",
       "4                      0.0                     0.0  ...                 0.0   \n",
       "5                      0.0                     0.0  ...                 0.0   \n",
       "\n",
       "   savings_DM1000+  employ_1-7years  employ_7+years  employ_unemployed  \\\n",
       "1              0.0              1.0             0.0                0.0   \n",
       "2              0.0              1.0             0.0                0.0   \n",
       "3              0.0              1.0             0.0                0.0   \n",
       "4              0.0              1.0             0.0                0.0   \n",
       "5              0.0              1.0             0.0                0.0   \n",
       "\n",
       "   sex_male  housing_own  housing_rent  tele_yes  foreign_german  \n",
       "1       0.0          1.0           0.0       0.0             0.0  \n",
       "2       1.0          1.0           0.0       0.0             0.0  \n",
       "3       1.0          0.0           0.0       0.0             0.0  \n",
       "4       1.0          0.0           0.0       0.0             0.0  \n",
       "5       1.0          0.0           0.0       1.0             0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# credit_processed = credit.copy()\n",
    "\n",
    "# # 初始化OneHotEncoder\n",
    "# encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first'可以避免多重共线性\n",
    "\n",
    "# # 选择要进行one-hot编码的列\n",
    "# categorical_columns = credit_processed.select_dtypes(include=['object']).columns\n",
    "\n",
    "# # 进行one-hot编码\n",
    "# encoded_features = encoder.fit_transform(credit_processed[categorical_columns])\n",
    "# encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# # 删除原始的分类列\n",
    "# credit_processed.drop(categorical_columns, axis=1, inplace=True)\n",
    "\n",
    "# # 将one-hot编码的列添加到数据框中\n",
    "# credit_processed = pd.concat([credit_processed, encoded_df], axis=1)\n",
    "\n",
    "# credit_processed = credit_processed.rename(columns={'Default': 'target'})\n",
    "\n",
    "# credit_processed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bf5c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkingstatus1': [('<DM0', 0),\n",
       "  ('DM0-200', 1),\n",
       "  ('DM200+', 2),\n",
       "  ('NoAccount', 3)],\n",
       " 'history': [('good', 0), ('poor', 1), ('terrible', 2)],\n",
       " 'purpose': [('biz', 0),\n",
       "  ('edu', 1),\n",
       "  ('goods/repair', 2),\n",
       "  ('newcar', 3),\n",
       "  ('usedcar', 4)],\n",
       " 'savings': [('DM0-100', 0), ('DM100-1000', 1), ('DM1000+', 2)],\n",
       " 'employ': [('0-1year', 0),\n",
       "  ('1-7years', 1),\n",
       "  ('7+years', 2),\n",
       "  ('unemployed', 3)],\n",
       " 'sex': [('female', 0), ('male', 1)],\n",
       " 'housing': [('forfree', 0), ('own', 1), ('rent', 2)],\n",
       " 'tele': [('no', 0), ('yes', 1)],\n",
       " 'foreign': [('foreign', 0), ('german', 1)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mappings = {}\n",
    "\n",
    "for column, encoder in label_encoders.items():\n",
    "    encoder_mappings[column] = list(zip(encoder.classes_, range(len(encoder.classes_))))\n",
    "\n",
    "encoder_mappings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09f1063",
   "metadata": {},
   "source": [
    "## xgboost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9c21dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "5       1\n",
      "       ..\n",
      "996     0\n",
      "997     0\n",
      "998     0\n",
      "999     1\n",
      "1000    0\n",
      "Name: target, Length: 1000, dtype: int64\n",
      "F1 Score: 0.5283018867924528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       147\n",
      "           1       0.53      0.53      0.53        53\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.75      0.75      0.75       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "credit_processed = credit_processed.dropna(subset=['target'])\n",
    "\n",
    "X = credit_processed.drop(columns=['target'])\n",
    "y = credit_processed['target']\n",
    "print(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=26)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', random_state=26)\n",
    "clf_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf_xgb.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e292c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['duration', 'amount', 'installment', 'residence', 'age', 'cards', 'liable']\n",
    "categorical_features = ['checkingstatus1', 'history', 'purpose', 'savings', 'employ', 'sex', 'housing', 'tele', 'foreign']\n",
    "immutable_features = ['sex', 'liable', 'foreign', 'purpose']\n",
    "non_decreasing_features = ['age', 'employ']\n",
    "correlated_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e4174",
   "metadata": {},
   "source": [
    "# ALIBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67857923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from alibi.explainers import Counterfactual\n",
    "from alibi.explainers import CounterfactualRLTabular, CounterfactualRL\n",
    "from alibi.explainers import CounterfactualProto\n",
    "#from alibi.datasets import fetch_adult\n",
    "from alibi.models.tensorflow import HeAE\n",
    "from alibi.models.tensorflow import Actor, Critic\n",
    "#from alibi.models.tensorflow import ADULTEncoder, ADULTDecoder\n",
    "from alibi.explainers.cfrl_base import Callback\n",
    "from alibi.explainers.backends.cfrl_tabular import get_he_preprocessor, get_statistics, \\\n",
    "    get_conditional_vector, apply_category_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2afbb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(X):\n",
    "    # The predict_proba method of the pipeline returns an array of shape (n_samples, 2)\n",
    "    # Return both columns as the CounterfactualProto explainer expects a probability for each class\n",
    "    pred_proba = loaded_model.predict_proba(X)\n",
    "    return np.hstack([1 - pred_proba[:, 1].reshape(-1, 1), pred_proba[:, 1].reshape(-1, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b6e6774",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming X_train is a pandas DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate the min and max values for the entire training dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m feature_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(X_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Assuming X_train is a pandas DataFrame\n",
    "X_train = X_train.drop(columns=['target'])\n",
    "\n",
    "# Calculate the min and max values for the entire training dataset\n",
    "feature_min = np.min(X_train, axis=0)\n",
    "feature_max = np.max(X_train, axis=0)\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Initialize CounterFactualProto\n",
    "shape = (1,) + X_train.shape[1:]\n",
    "# Initialize the explainer\n",
    "cf = CounterfactualProto(predict_fn, shape, use_kdtree=True, theta=10., max_iterations=1000,\n",
    "                         feature_range=(feature_min, feature_max), \n",
    "                         c_init=1., c_steps=10)\n",
    "cf.fit(X_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9226e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n",
      "No counterfactual found!\n"
     ]
    }
   ],
   "source": [
    "instances = X_test[y_pred == 1].values\n",
    "\n",
    "# List to store counterfactuals\n",
    "counterfactuals = []\n",
    "\n",
    "start_time = time.time()\n",
    "# Loop through each instance and generate counterfactual\n",
    "\n",
    "\n",
    "for instance in instances:\n",
    "    explanation = cf.explain(instance.reshape(1, -1))\n",
    "    \n",
    "    # Check if a counterfactual was found\n",
    "    if explanation.cf is not None:\n",
    "        counterfactuals.append(explanation.cf['X'])\n",
    "    else:\n",
    "        # You can append a placeholder or simply skip\n",
    "        # Here, I'm appending None to indicate no counterfactual was found for this instance\n",
    "        counterfactuals.append(None)\n",
    "\n",
    "# Convert the list of counterfactuals to a numpy array for further processing\n",
    "# Note: If you appended None for missing counterfactuals, you might want to handle them before converting to an array\n",
    "# counterfactuals_array = np.array(counterfactuals).squeeze()\n",
    "# Strategy 1: Replace with a specific value\n",
    "counterfactuals_replaced = [cf if cf is not None else -1 for cf in counterfactuals]\n",
    "\n",
    "counterfactuals_mean = [cf if cf is not None else mean_value for cf in counterfactuals]\n",
    "\n",
    "# Convert the list of counterfactuals to a numpy array\n",
    "counterfactuals_array_replaced = np.array(counterfactuals_replaced).squeeze()\n",
    "\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef12f08",
   "metadata": {},
   "source": [
    "# Alibi rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe21aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CreditEncoder(keras.Model):\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "        super(CreditEncoder, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(hidden_dim, activation='relu')\n",
    "        self.dense2 = keras.layers.Dense(latent_dim, activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fef1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditDecoder(keras.Model):\n",
    "    def __init__(self, hidden_dim, output_dims):\n",
    "        super(CreditDecoder, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(hidden_dim, activation='relu')\n",
    "        self.outputs_list = [keras.layers.Dense(dim, activation='sigmoid') for dim in output_dims]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return [output_layer(x) for output_layer in self.outputs_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8892efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeAE(keras.Model):\n",
    "    def __init__(self, encoder: keras.Model, decoder: keras.Model):\n",
    "        super(HeAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8056afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义特征类型\n",
    "feature_types = {\n",
    "    \"checkingstatus1\": str,\n",
    "    \"history\": str,\n",
    "    \"purpose\": str,\n",
    "    \"savings\": str,\n",
    "    \"employ\": str,\n",
    "    \"sex\": str,\n",
    "    \"housing\": str,\n",
    "    \"tele\": str,\n",
    "    \"foreign\": str,\n",
    "    \"duration\": int,\n",
    "    \"amount\": int,\n",
    "    \"installment\": int,\n",
    "    \"residence\": int,\n",
    "    \"age\": int,\n",
    "    \"cards\": int,\n",
    "    \"liable\": int\n",
    "}\n",
    "\n",
    "# 定义预处理函数\n",
    "def credit_preprocessor(data):\n",
    "    processed_data = data.copy()\n",
    "    for column, dtype in feature_types.items():\n",
    "        if dtype == str:\n",
    "            processed_data[column] = label_encoders[column].transform(processed_data[column])\n",
    "    return processed_data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab95a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_inv_preprocessor(data):\n",
    "    inv_processed_data = data.copy()\n",
    "    for column, dtype in feature_types.items():\n",
    "        if dtype == str:\n",
    "            inv_processed_data[column] = label_encoders[column].inverse_transform(inv_processed_data[column].astype(int))\n",
    "    return inv_processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498944bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credit_preprocessor(X, feature_names, category_map, feature_types):\n",
    "    # 在这里定义您的预处理逻辑\n",
    "    def preprocessor(data):\n",
    "        # 对数据进行预处理\n",
    "        return processed_data\n",
    "\n",
    "    def inv_preprocessor(data):\n",
    "        # 对数据进行反向预处理\n",
    "        return inv_processed_data\n",
    "\n",
    "    return preprocessor, inv_preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f21b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数值特征和分类特征\n",
    "numerical_features = ['duration', 'amount', 'installment', 'residence', 'age', 'cards', 'liable']\n",
    "categorical_features = ['checkingstatus1', 'history', 'purpose', 'savings', 'employ', 'sex', 'housing', 'tele', 'foreign']\n",
    "\n",
    "# 获取这些特征的索引，同时排除第一列（目标列）\n",
    "numerical_ids = [credit.columns.get_loc(feature) - 1 for feature in numerical_features]\n",
    "categorical_ids = [credit.columns.get_loc(feature) - 1 for feature in categorical_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e25891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义常数\n",
    "EPOCHS = 50\n",
    "HIDDEN_DIM = 128\n",
    "LATENT_DIM = 15\n",
    "\n",
    "# 根据您的数据定义输出维度\n",
    "OUTPUT_DIMS = [len(numerical_ids)]\n",
    "OUTPUT_DIMS += [len(encoder_mappings[cat_id]) for cat_id in categorical_features]\n",
    "\n",
    "# 定义异构自编码器\n",
    "heae = HeAE(encoder=CreditEncoder(hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM),\n",
    "            decoder=CreditDecoder(hidden_dim=HIDDEN_DIM, output_dims=OUTPUT_DIMS))\n",
    "\n",
    "# ... 其他代码（如损失函数、优化器、训练等） ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e0a6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "he_loss = [keras.losses.MeanSquaredError()]\n",
    "he_loss_weights = [1.]\n",
    "\n",
    "# 添加分类损失\n",
    "for i in range(len(categorical_features)):\n",
    "    he_loss.append(keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "    he_loss_weights.append(1./len(categorical_features))\n",
    "\n",
    "# 定义指标\n",
    "metrics = {}\n",
    "for i, cat_name in enumerate(categorical_features):\n",
    "    metrics.update({f\"output_{i+2}\": keras.metrics.SparseCategoricalAccuracy()})\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e20004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化标准化器\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def heae_preprocessor(data):\n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # 对数值特征进行标准化\n",
    "    processed_data[numerical_features] = scaler.fit_transform(processed_data[numerical_features])\n",
    "    \n",
    "    # 将分类特征转换为整数编码\n",
    "    for column in categorical_features:\n",
    "        processed_data[column] = label_encoders[column].transform(processed_data[column])\n",
    "    \n",
    "    return processed_data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b4d3d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 9ms/step - loss: 2.6452 - output_1_loss: 1.5857 - output_2_loss: 1.3406 - output_3_loss: 1.0923 - output_4_loss: 1.5293 - output_5_loss: 1.0988 - output_6_loss: 1.4171 - output_7_loss: 0.6793 - output_8_loss: 0.9882 - output_9_loss: 0.7156 - output_10_loss: 0.6736 - output_2_sparse_categorical_accuracy: 0.3958 - output_3_sparse_categorical_accuracy: 0.2812 - output_4_sparse_categorical_accuracy: 0.4857 - output_5_sparse_categorical_accuracy: 0.3359 - output_6_sparse_categorical_accuracy: 0.1654 - output_7_sparse_categorical_accuracy: 0.5664 - output_8_sparse_categorical_accuracy: 0.6953 - output_9_sparse_categorical_accuracy: 0.5013 - output_10_sparse_categorical_accuracy: 0.6341\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4571 - output_1_loss: 1.4736 - output_2_loss: 1.2838 - output_3_loss: 1.0242 - output_4_loss: 1.4588 - output_5_loss: 0.9847 - output_6_loss: 1.3231 - output_7_loss: 0.6053 - output_8_loss: 0.9057 - output_9_loss: 0.7102 - output_10_loss: 0.5556 - output_2_sparse_categorical_accuracy: 0.3932 - output_3_sparse_categorical_accuracy: 0.4740 - output_4_sparse_categorical_accuracy: 0.4883 - output_5_sparse_categorical_accuracy: 0.7526 - output_6_sparse_categorical_accuracy: 0.4036 - output_7_sparse_categorical_accuracy: 0.7005 - output_8_sparse_categorical_accuracy: 0.7148 - output_9_sparse_categorical_accuracy: 0.5859 - output_10_sparse_categorical_accuracy: 0.9479\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2637 - output_1_loss: 1.3567 - output_2_loss: 1.2404 - output_3_loss: 0.9430 - output_4_loss: 1.3889 - output_5_loss: 0.8202 - output_6_loss: 1.2340 - output_7_loss: 0.5994 - output_8_loss: 0.8283 - output_9_loss: 0.7103 - output_10_loss: 0.3982 - output_2_sparse_categorical_accuracy: 0.4010 - output_3_sparse_categorical_accuracy: 0.6198 - output_4_sparse_categorical_accuracy: 0.4922 - output_5_sparse_categorical_accuracy: 0.7812 - output_6_sparse_categorical_accuracy: 0.5065 - output_7_sparse_categorical_accuracy: 0.6966 - output_8_sparse_categorical_accuracy: 0.7122 - output_9_sparse_categorical_accuracy: 0.5951 - output_10_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0745 - output_1_loss: 1.2150 - output_2_loss: 1.2400 - output_3_loss: 0.8845 - output_4_loss: 1.3581 - output_5_loss: 0.6863 - output_6_loss: 1.2043 - output_7_loss: 0.6236 - output_8_loss: 0.7855 - output_9_loss: 0.7059 - output_10_loss: 0.2466 - output_2_sparse_categorical_accuracy: 0.3932 - output_3_sparse_categorical_accuracy: 0.6146 - output_4_sparse_categorical_accuracy: 0.4961 - output_5_sparse_categorical_accuracy: 0.7878 - output_6_sparse_categorical_accuracy: 0.5091 - output_7_sparse_categorical_accuracy: 0.7005 - output_8_sparse_categorical_accuracy: 0.7201 - output_9_sparse_categorical_accuracy: 0.5924 - output_10_sparse_categorical_accuracy: 0.9635\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9744 - output_1_loss: 1.1287 - output_2_loss: 1.1989 - output_3_loss: 0.8690 - output_4_loss: 1.3681 - output_5_loss: 0.6822 - output_6_loss: 1.2032 - output_7_loss: 0.6159 - output_8_loss: 0.8030 - output_9_loss: 0.6914 - output_10_loss: 0.1797 - output_2_sparse_categorical_accuracy: 0.4036 - output_3_sparse_categorical_accuracy: 0.6237 - output_4_sparse_categorical_accuracy: 0.4909 - output_5_sparse_categorical_accuracy: 0.7826 - output_6_sparse_categorical_accuracy: 0.5104 - output_7_sparse_categorical_accuracy: 0.6992 - output_8_sparse_categorical_accuracy: 0.7122 - output_9_sparse_categorical_accuracy: 0.5521 - output_10_sparse_categorical_accuracy: 0.9635\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9275 - output_1_loss: 1.1037 - output_2_loss: 1.1474 - output_3_loss: 0.8641 - output_4_loss: 1.3410 - output_5_loss: 0.6575 - output_6_loss: 1.1878 - output_7_loss: 0.5875 - output_8_loss: 0.7628 - output_9_loss: 0.6853 - output_10_loss: 0.1816 - output_2_sparse_categorical_accuracy: 0.4401 - output_3_sparse_categorical_accuracy: 0.6198 - output_4_sparse_categorical_accuracy: 0.4857 - output_5_sparse_categorical_accuracy: 0.7878 - output_6_sparse_categorical_accuracy: 0.5299 - output_7_sparse_categorical_accuracy: 0.6953 - output_8_sparse_categorical_accuracy: 0.7161 - output_9_sparse_categorical_accuracy: 0.5794 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8815 - output_1_loss: 1.0782 - output_2_loss: 1.1161 - output_3_loss: 0.8561 - output_4_loss: 1.2863 - output_5_loss: 0.6427 - output_6_loss: 1.1618 - output_7_loss: 0.5727 - output_8_loss: 0.7409 - output_9_loss: 0.6659 - output_10_loss: 0.1876 - output_2_sparse_categorical_accuracy: 0.5117 - output_3_sparse_categorical_accuracy: 0.6250 - output_4_sparse_categorical_accuracy: 0.4870 - output_5_sparse_categorical_accuracy: 0.7826 - output_6_sparse_categorical_accuracy: 0.5586 - output_7_sparse_categorical_accuracy: 0.7044 - output_8_sparse_categorical_accuracy: 0.7161 - output_9_sparse_categorical_accuracy: 0.6042 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8425 - output_1_loss: 1.0610 - output_2_loss: 1.0622 - output_3_loss: 0.8308 - output_4_loss: 1.2668 - output_5_loss: 0.6298 - output_6_loss: 1.1216 - output_7_loss: 0.5542 - output_8_loss: 0.7380 - output_9_loss: 0.6431 - output_10_loss: 0.1872 - output_2_sparse_categorical_accuracy: 0.5625 - output_3_sparse_categorical_accuracy: 0.6185 - output_4_sparse_categorical_accuracy: 0.4896 - output_5_sparse_categorical_accuracy: 0.7865 - output_6_sparse_categorical_accuracy: 0.5638 - output_7_sparse_categorical_accuracy: 0.7005 - output_8_sparse_categorical_accuracy: 0.7227 - output_9_sparse_categorical_accuracy: 0.6445 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8029 - output_1_loss: 1.0405 - output_2_loss: 0.9994 - output_3_loss: 0.8102 - output_4_loss: 1.2523 - output_5_loss: 0.6149 - output_6_loss: 1.1079 - output_7_loss: 0.5412 - output_8_loss: 0.7283 - output_9_loss: 0.6169 - output_10_loss: 0.1900 - output_2_sparse_categorical_accuracy: 0.5560 - output_3_sparse_categorical_accuracy: 0.6133 - output_4_sparse_categorical_accuracy: 0.5052 - output_5_sparse_categorical_accuracy: 0.7826 - output_6_sparse_categorical_accuracy: 0.5391 - output_7_sparse_categorical_accuracy: 0.7018 - output_8_sparse_categorical_accuracy: 0.7174 - output_9_sparse_categorical_accuracy: 0.6745 - output_10_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7679 - output_1_loss: 1.0283 - output_2_loss: 0.9475 - output_3_loss: 0.7858 - output_4_loss: 1.2334 - output_5_loss: 0.5986 - output_6_loss: 1.0729 - output_7_loss: 0.5248 - output_8_loss: 0.7121 - output_9_loss: 0.5970 - output_10_loss: 0.1846 - output_2_sparse_categorical_accuracy: 0.5651 - output_3_sparse_categorical_accuracy: 0.6315 - output_4_sparse_categorical_accuracy: 0.5013 - output_5_sparse_categorical_accuracy: 0.7839 - output_6_sparse_categorical_accuracy: 0.5690 - output_7_sparse_categorical_accuracy: 0.7070 - output_8_sparse_categorical_accuracy: 0.7227 - output_9_sparse_categorical_accuracy: 0.6745 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7366 - output_1_loss: 1.0213 - output_2_loss: 0.8775 - output_3_loss: 0.7648 - output_4_loss: 1.2141 - output_5_loss: 0.5760 - output_6_loss: 1.0484 - output_7_loss: 0.5056 - output_8_loss: 0.6970 - output_9_loss: 0.5731 - output_10_loss: 0.1811 - output_2_sparse_categorical_accuracy: 0.6263 - output_3_sparse_categorical_accuracy: 0.6680 - output_4_sparse_categorical_accuracy: 0.5000 - output_5_sparse_categorical_accuracy: 0.7839 - output_6_sparse_categorical_accuracy: 0.5938 - output_7_sparse_categorical_accuracy: 0.7331 - output_8_sparse_categorical_accuracy: 0.7292 - output_9_sparse_categorical_accuracy: 0.7005 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6968 - output_1_loss: 1.0052 - output_2_loss: 0.8291 - output_3_loss: 0.7347 - output_4_loss: 1.1792 - output_5_loss: 0.5677 - output_6_loss: 1.0168 - output_7_loss: 0.4931 - output_8_loss: 0.6788 - output_9_loss: 0.5491 - output_10_loss: 0.1757 - output_2_sparse_categorical_accuracy: 0.6419 - output_3_sparse_categorical_accuracy: 0.6927 - output_4_sparse_categorical_accuracy: 0.5195 - output_5_sparse_categorical_accuracy: 0.7826 - output_6_sparse_categorical_accuracy: 0.5859 - output_7_sparse_categorical_accuracy: 0.7539 - output_8_sparse_categorical_accuracy: 0.7331 - output_9_sparse_categorical_accuracy: 0.7292 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6610 - output_1_loss: 0.9968 - output_2_loss: 0.7536 - output_3_loss: 0.7088 - output_4_loss: 1.1589 - output_5_loss: 0.5361 - output_6_loss: 0.9855 - output_7_loss: 0.4763 - output_8_loss: 0.6685 - output_9_loss: 0.5303 - output_10_loss: 0.1595 - output_2_sparse_categorical_accuracy: 0.7161 - output_3_sparse_categorical_accuracy: 0.7044 - output_4_sparse_categorical_accuracy: 0.5352 - output_5_sparse_categorical_accuracy: 0.7891 - output_6_sparse_categorical_accuracy: 0.6016 - output_7_sparse_categorical_accuracy: 0.7878 - output_8_sparse_categorical_accuracy: 0.7422 - output_9_sparse_categorical_accuracy: 0.7565 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6138 - output_1_loss: 0.9790 - output_2_loss: 0.6932 - output_3_loss: 0.6782 - output_4_loss: 1.1137 - output_5_loss: 0.5003 - output_6_loss: 0.9506 - output_7_loss: 0.4572 - output_8_loss: 0.6540 - output_9_loss: 0.5043 - output_10_loss: 0.1617 - output_2_sparse_categorical_accuracy: 0.7591 - output_3_sparse_categorical_accuracy: 0.7396 - output_4_sparse_categorical_accuracy: 0.5469 - output_5_sparse_categorical_accuracy: 0.8047 - output_6_sparse_categorical_accuracy: 0.6055 - output_7_sparse_categorical_accuracy: 0.7865 - output_8_sparse_categorical_accuracy: 0.7396 - output_9_sparse_categorical_accuracy: 0.7799 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5908 - output_1_loss: 0.9858 - output_2_loss: 0.6294 - output_3_loss: 0.6402 - output_4_loss: 1.0817 - output_5_loss: 0.4706 - output_6_loss: 0.9278 - output_7_loss: 0.4307 - output_8_loss: 0.6328 - output_9_loss: 0.4727 - output_10_loss: 0.1590 - output_2_sparse_categorical_accuracy: 0.8021 - output_3_sparse_categorical_accuracy: 0.7435 - output_4_sparse_categorical_accuracy: 0.5612 - output_5_sparse_categorical_accuracy: 0.8047 - output_6_sparse_categorical_accuracy: 0.5964 - output_7_sparse_categorical_accuracy: 0.8268 - output_8_sparse_categorical_accuracy: 0.7435 - output_9_sparse_categorical_accuracy: 0.7982 - output_10_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5513 - output_1_loss: 0.9779 - output_2_loss: 0.5711 - output_3_loss: 0.6233 - output_4_loss: 1.0406 - output_5_loss: 0.4355 - output_6_loss: 0.8916 - output_7_loss: 0.3991 - output_8_loss: 0.6160 - output_9_loss: 0.4369 - output_10_loss: 0.1465 - output_2_sparse_categorical_accuracy: 0.8190 - output_3_sparse_categorical_accuracy: 0.7643 - output_4_sparse_categorical_accuracy: 0.5951 - output_5_sparse_categorical_accuracy: 0.8151 - output_6_sparse_categorical_accuracy: 0.6042 - output_7_sparse_categorical_accuracy: 0.8503 - output_8_sparse_categorical_accuracy: 0.7448 - output_9_sparse_categorical_accuracy: 0.8320 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5162 - output_1_loss: 0.9707 - output_2_loss: 0.5249 - output_3_loss: 0.6017 - output_4_loss: 1.0015 - output_5_loss: 0.4106 - output_6_loss: 0.8487 - output_7_loss: 0.3760 - output_8_loss: 0.6034 - output_9_loss: 0.4106 - output_10_loss: 0.1317 - output_2_sparse_categorical_accuracy: 0.8633 - output_3_sparse_categorical_accuracy: 0.7591 - output_4_sparse_categorical_accuracy: 0.6016 - output_5_sparse_categorical_accuracy: 0.8164 - output_6_sparse_categorical_accuracy: 0.6263 - output_7_sparse_categorical_accuracy: 0.8529 - output_8_sparse_categorical_accuracy: 0.7435 - output_9_sparse_categorical_accuracy: 0.8503 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4708 - output_1_loss: 0.9517 - output_2_loss: 0.4828 - output_3_loss: 0.5853 - output_4_loss: 0.9598 - output_5_loss: 0.3784 - output_6_loss: 0.8083 - output_7_loss: 0.3522 - output_8_loss: 0.5990 - output_9_loss: 0.3782 - output_10_loss: 0.1283 - output_2_sparse_categorical_accuracy: 0.8724 - output_3_sparse_categorical_accuracy: 0.7734 - output_4_sparse_categorical_accuracy: 0.6406 - output_5_sparse_categorical_accuracy: 0.8542 - output_6_sparse_categorical_accuracy: 0.6510 - output_7_sparse_categorical_accuracy: 0.8711 - output_8_sparse_categorical_accuracy: 0.7500 - output_9_sparse_categorical_accuracy: 0.8737 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4362 - output_1_loss: 0.9475 - output_2_loss: 0.4319 - output_3_loss: 0.5624 - output_4_loss: 0.9293 - output_5_loss: 0.3420 - output_6_loss: 0.7675 - output_7_loss: 0.3183 - output_8_loss: 0.5758 - output_9_loss: 0.3456 - output_10_loss: 0.1254 - output_2_sparse_categorical_accuracy: 0.8971 - output_3_sparse_categorical_accuracy: 0.7812 - output_4_sparse_categorical_accuracy: 0.6341 - output_5_sparse_categorical_accuracy: 0.8516 - output_6_sparse_categorical_accuracy: 0.6576 - output_7_sparse_categorical_accuracy: 0.8828 - output_8_sparse_categorical_accuracy: 0.7656 - output_9_sparse_categorical_accuracy: 0.8854 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4087 - output_1_loss: 0.9451 - output_2_loss: 0.4000 - output_3_loss: 0.5469 - output_4_loss: 0.8964 - output_5_loss: 0.3039 - output_6_loss: 0.7330 - output_7_loss: 0.2964 - output_8_loss: 0.5670 - output_9_loss: 0.3106 - output_10_loss: 0.1180 - output_2_sparse_categorical_accuracy: 0.9010 - output_3_sparse_categorical_accuracy: 0.7956 - output_4_sparse_categorical_accuracy: 0.6758 - output_5_sparse_categorical_accuracy: 0.8750 - output_6_sparse_categorical_accuracy: 0.6953 - output_7_sparse_categorical_accuracy: 0.9049 - output_8_sparse_categorical_accuracy: 0.7826 - output_9_sparse_categorical_accuracy: 0.9036 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3677 - output_1_loss: 0.9316 - output_2_loss: 0.3677 - output_3_loss: 0.5242 - output_4_loss: 0.8554 - output_5_loss: 0.2799 - output_6_loss: 0.6819 - output_7_loss: 0.2642 - output_8_loss: 0.5502 - output_9_loss: 0.2828 - output_10_loss: 0.1187 - output_2_sparse_categorical_accuracy: 0.9010 - output_3_sparse_categorical_accuracy: 0.7982 - output_4_sparse_categorical_accuracy: 0.6732 - output_5_sparse_categorical_accuracy: 0.8750 - output_6_sparse_categorical_accuracy: 0.7135 - output_7_sparse_categorical_accuracy: 0.9310 - output_8_sparse_categorical_accuracy: 0.7812 - output_9_sparse_categorical_accuracy: 0.9089 - output_10_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3314 - output_1_loss: 0.9224 - output_2_loss: 0.3346 - output_3_loss: 0.5056 - output_4_loss: 0.8222 - output_5_loss: 0.2537 - output_6_loss: 0.6449 - output_7_loss: 0.2318 - output_8_loss: 0.5305 - output_9_loss: 0.2449 - output_10_loss: 0.1131 - output_2_sparse_categorical_accuracy: 0.9102 - output_3_sparse_categorical_accuracy: 0.8164 - output_4_sparse_categorical_accuracy: 0.6797 - output_5_sparse_categorical_accuracy: 0.9154 - output_6_sparse_categorical_accuracy: 0.7604 - output_7_sparse_categorical_accuracy: 0.9271 - output_8_sparse_categorical_accuracy: 0.7982 - output_9_sparse_categorical_accuracy: 0.9310 - output_10_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3180 - output_1_loss: 0.9299 - output_2_loss: 0.3092 - output_3_loss: 0.5032 - output_4_loss: 0.7886 - output_5_loss: 0.2332 - output_6_loss: 0.6089 - output_7_loss: 0.2019 - output_8_loss: 0.5161 - output_9_loss: 0.2249 - output_10_loss: 0.1066 - output_2_sparse_categorical_accuracy: 0.9141 - output_3_sparse_categorical_accuracy: 0.8073 - output_4_sparse_categorical_accuracy: 0.6979 - output_5_sparse_categorical_accuracy: 0.8945 - output_6_sparse_categorical_accuracy: 0.7760 - output_7_sparse_categorical_accuracy: 0.9531 - output_8_sparse_categorical_accuracy: 0.7891 - output_9_sparse_categorical_accuracy: 0.9323 - output_10_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2825 - output_1_loss: 0.9197 - output_2_loss: 0.2891 - output_3_loss: 0.4729 - output_4_loss: 0.7619 - output_5_loss: 0.2100 - output_6_loss: 0.5626 - output_7_loss: 0.1758 - output_8_loss: 0.4947 - output_9_loss: 0.1978 - output_10_loss: 0.1003 - output_2_sparse_categorical_accuracy: 0.9180 - output_3_sparse_categorical_accuracy: 0.8320 - output_4_sparse_categorical_accuracy: 0.7305 - output_5_sparse_categorical_accuracy: 0.9323 - output_6_sparse_categorical_accuracy: 0.7956 - output_7_sparse_categorical_accuracy: 0.9505 - output_8_sparse_categorical_accuracy: 0.8138 - output_9_sparse_categorical_accuracy: 0.9401 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2567 - output_1_loss: 0.9165 - output_2_loss: 0.2667 - output_3_loss: 0.4499 - output_4_loss: 0.7443 - output_5_loss: 0.1927 - output_6_loss: 0.5266 - output_7_loss: 0.1480 - output_8_loss: 0.4792 - output_9_loss: 0.1654 - output_10_loss: 0.0890 - output_2_sparse_categorical_accuracy: 0.9245 - output_3_sparse_categorical_accuracy: 0.8333 - output_4_sparse_categorical_accuracy: 0.7279 - output_5_sparse_categorical_accuracy: 0.9323 - output_6_sparse_categorical_accuracy: 0.8281 - output_7_sparse_categorical_accuracy: 0.9688 - output_8_sparse_categorical_accuracy: 0.8164 - output_9_sparse_categorical_accuracy: 0.9583 - output_10_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2384 - output_1_loss: 0.9211 - output_2_loss: 0.2478 - output_3_loss: 0.4209 - output_4_loss: 0.7091 - output_5_loss: 0.1722 - output_6_loss: 0.4865 - output_7_loss: 0.1311 - output_8_loss: 0.4643 - output_9_loss: 0.1402 - output_10_loss: 0.0841 - output_2_sparse_categorical_accuracy: 0.9271 - output_3_sparse_categorical_accuracy: 0.8464 - output_4_sparse_categorical_accuracy: 0.7357 - output_5_sparse_categorical_accuracy: 0.9375 - output_6_sparse_categorical_accuracy: 0.8294 - output_7_sparse_categorical_accuracy: 0.9714 - output_8_sparse_categorical_accuracy: 0.8190 - output_9_sparse_categorical_accuracy: 0.9714 - output_10_sparse_categorical_accuracy: 0.9674\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2109 - output_1_loss: 0.9140 - output_2_loss: 0.2328 - output_3_loss: 0.4056 - output_4_loss: 0.6711 - output_5_loss: 0.1541 - output_6_loss: 0.4548 - output_7_loss: 0.1132 - output_8_loss: 0.4494 - output_9_loss: 0.1135 - output_10_loss: 0.0777 - output_2_sparse_categorical_accuracy: 0.9440 - output_3_sparse_categorical_accuracy: 0.8568 - output_4_sparse_categorical_accuracy: 0.7578 - output_5_sparse_categorical_accuracy: 0.9518 - output_6_sparse_categorical_accuracy: 0.8581 - output_7_sparse_categorical_accuracy: 0.9753 - output_8_sparse_categorical_accuracy: 0.8281 - output_9_sparse_categorical_accuracy: 0.9831 - output_10_sparse_categorical_accuracy: 0.9714\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1927 - output_1_loss: 0.9136 - output_2_loss: 0.2189 - output_3_loss: 0.3860 - output_4_loss: 0.6498 - output_5_loss: 0.1414 - output_6_loss: 0.4190 - output_7_loss: 0.0987 - output_8_loss: 0.4252 - output_9_loss: 0.0989 - output_10_loss: 0.0737 - output_2_sparse_categorical_accuracy: 0.9414 - output_3_sparse_categorical_accuracy: 0.8581 - output_4_sparse_categorical_accuracy: 0.7760 - output_5_sparse_categorical_accuracy: 0.9622 - output_6_sparse_categorical_accuracy: 0.8802 - output_7_sparse_categorical_accuracy: 0.9831 - output_8_sparse_categorical_accuracy: 0.8438 - output_9_sparse_categorical_accuracy: 0.9870 - output_10_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1747 - output_1_loss: 0.9153 - output_2_loss: 0.1994 - output_3_loss: 0.3545 - output_4_loss: 0.6414 - output_5_loss: 0.1241 - output_6_loss: 0.3787 - output_7_loss: 0.0814 - output_8_loss: 0.4077 - output_9_loss: 0.0786 - output_10_loss: 0.0683 - output_2_sparse_categorical_accuracy: 0.9492 - output_3_sparse_categorical_accuracy: 0.8776 - output_4_sparse_categorical_accuracy: 0.7500 - output_5_sparse_categorical_accuracy: 0.9622 - output_6_sparse_categorical_accuracy: 0.8880 - output_7_sparse_categorical_accuracy: 0.9857 - output_8_sparse_categorical_accuracy: 0.8398 - output_9_sparse_categorical_accuracy: 0.9909 - output_10_sparse_categorical_accuracy: 0.9688\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1435 - output_1_loss: 0.8999 - output_2_loss: 0.1875 - output_3_loss: 0.3415 - output_4_loss: 0.6078 - output_5_loss: 0.1176 - output_6_loss: 0.3432 - output_7_loss: 0.0723 - output_8_loss: 0.3926 - output_9_loss: 0.0695 - output_10_loss: 0.0604 - output_2_sparse_categorical_accuracy: 0.9531 - output_3_sparse_categorical_accuracy: 0.8828 - output_4_sparse_categorical_accuracy: 0.7930 - output_5_sparse_categorical_accuracy: 0.9688 - output_6_sparse_categorical_accuracy: 0.9049 - output_7_sparse_categorical_accuracy: 0.9909 - output_8_sparse_categorical_accuracy: 0.8424 - output_9_sparse_categorical_accuracy: 0.9935 - output_10_sparse_categorical_accuracy: 0.9831\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1198 - output_1_loss: 0.8920 - output_2_loss: 0.1783 - output_3_loss: 0.3160 - output_4_loss: 0.5759 - output_5_loss: 0.1035 - output_6_loss: 0.3178 - output_7_loss: 0.0616 - output_8_loss: 0.3855 - output_9_loss: 0.0561 - output_10_loss: 0.0555 - output_2_sparse_categorical_accuracy: 0.9492 - output_3_sparse_categorical_accuracy: 0.8893 - output_4_sparse_categorical_accuracy: 0.7969 - output_5_sparse_categorical_accuracy: 0.9727 - output_6_sparse_categorical_accuracy: 0.9023 - output_7_sparse_categorical_accuracy: 0.9935 - output_8_sparse_categorical_accuracy: 0.8555 - output_9_sparse_categorical_accuracy: 0.9961 - output_10_sparse_categorical_accuracy: 0.9831\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1098 - output_1_loss: 0.8957 - output_2_loss: 0.1617 - output_3_loss: 0.2935 - output_4_loss: 0.5638 - output_5_loss: 0.0913 - output_6_loss: 0.2890 - output_7_loss: 0.0531 - output_8_loss: 0.3763 - output_9_loss: 0.0477 - output_10_loss: 0.0506 - output_2_sparse_categorical_accuracy: 0.9622 - output_3_sparse_categorical_accuracy: 0.8971 - output_4_sparse_categorical_accuracy: 0.7969 - output_5_sparse_categorical_accuracy: 0.9766 - output_6_sparse_categorical_accuracy: 0.9193 - output_7_sparse_categorical_accuracy: 0.9922 - output_8_sparse_categorical_accuracy: 0.8516 - output_9_sparse_categorical_accuracy: 0.9974 - output_10_sparse_categorical_accuracy: 0.9831\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0999 - output_1_loss: 0.8967 - output_2_loss: 0.1546 - output_3_loss: 0.2809 - output_4_loss: 0.5413 - output_5_loss: 0.0853 - output_6_loss: 0.2621 - output_7_loss: 0.0464 - output_8_loss: 0.3694 - output_9_loss: 0.0423 - output_10_loss: 0.0463 - output_2_sparse_categorical_accuracy: 0.9518 - output_3_sparse_categorical_accuracy: 0.9010 - output_4_sparse_categorical_accuracy: 0.8073 - output_5_sparse_categorical_accuracy: 0.9766 - output_6_sparse_categorical_accuracy: 0.9284 - output_7_sparse_categorical_accuracy: 0.9961 - output_8_sparse_categorical_accuracy: 0.8594 - output_9_sparse_categorical_accuracy: 0.9961 - output_10_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0836 - output_1_loss: 0.8915 - output_2_loss: 0.1490 - output_3_loss: 0.2606 - output_4_loss: 0.5269 - output_5_loss: 0.0827 - output_6_loss: 0.2389 - output_7_loss: 0.0415 - output_8_loss: 0.3471 - output_9_loss: 0.0370 - output_10_loss: 0.0453 - output_2_sparse_categorical_accuracy: 0.9701 - output_3_sparse_categorical_accuracy: 0.9102 - output_4_sparse_categorical_accuracy: 0.7982 - output_5_sparse_categorical_accuracy: 0.9766 - output_6_sparse_categorical_accuracy: 0.9323 - output_7_sparse_categorical_accuracy: 0.9935 - output_8_sparse_categorical_accuracy: 0.8711 - output_9_sparse_categorical_accuracy: 0.9961 - output_10_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0689 - output_1_loss: 0.8883 - output_2_loss: 0.1371 - output_3_loss: 0.2474 - output_4_loss: 0.4952 - output_5_loss: 0.0715 - output_6_loss: 0.2243 - output_7_loss: 0.0365 - output_8_loss: 0.3408 - output_9_loss: 0.0321 - output_10_loss: 0.0398 - output_2_sparse_categorical_accuracy: 0.9622 - output_3_sparse_categorical_accuracy: 0.9141 - output_4_sparse_categorical_accuracy: 0.8294 - output_5_sparse_categorical_accuracy: 0.9857 - output_6_sparse_categorical_accuracy: 0.9362 - output_7_sparse_categorical_accuracy: 0.9974 - output_8_sparse_categorical_accuracy: 0.8672 - output_9_sparse_categorical_accuracy: 0.9961 - output_10_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0560 - output_1_loss: 0.8860 - output_2_loss: 0.1307 - output_3_loss: 0.2320 - output_4_loss: 0.4796 - output_5_loss: 0.0686 - output_6_loss: 0.2016 - output_7_loss: 0.0341 - output_8_loss: 0.3164 - output_9_loss: 0.0282 - output_10_loss: 0.0386 - output_2_sparse_categorical_accuracy: 0.9635 - output_3_sparse_categorical_accuracy: 0.9167 - output_4_sparse_categorical_accuracy: 0.8268 - output_5_sparse_categorical_accuracy: 0.9818 - output_6_sparse_categorical_accuracy: 0.9440 - output_7_sparse_categorical_accuracy: 0.9961 - output_8_sparse_categorical_accuracy: 0.8815 - output_9_sparse_categorical_accuracy: 0.9987 - output_10_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0433 - output_1_loss: 0.8842 - output_2_loss: 0.1266 - output_3_loss: 0.2069 - output_4_loss: 0.4505 - output_5_loss: 0.0653 - output_6_loss: 0.1913 - output_7_loss: 0.0303 - output_8_loss: 0.3026 - output_9_loss: 0.0242 - output_10_loss: 0.0344 - output_2_sparse_categorical_accuracy: 0.9674 - output_3_sparse_categorical_accuracy: 0.9427 - output_4_sparse_categorical_accuracy: 0.8372 - output_5_sparse_categorical_accuracy: 0.9857 - output_6_sparse_categorical_accuracy: 0.9414 - output_7_sparse_categorical_accuracy: 0.9974 - output_8_sparse_categorical_accuracy: 0.8893 - output_9_sparse_categorical_accuracy: 0.9987 - output_10_sparse_categorical_accuracy: 0.9922\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0376 - output_1_loss: 0.8848 - output_2_loss: 0.1174 - output_3_loss: 0.1950 - output_4_loss: 0.4440 - output_5_loss: 0.0577 - output_6_loss: 0.1800 - output_7_loss: 0.0284 - output_8_loss: 0.2987 - output_9_loss: 0.0222 - output_10_loss: 0.0318 - output_2_sparse_categorical_accuracy: 0.9779 - output_3_sparse_categorical_accuracy: 0.9297 - output_4_sparse_categorical_accuracy: 0.8385 - output_5_sparse_categorical_accuracy: 0.9883 - output_6_sparse_categorical_accuracy: 0.9544 - output_7_sparse_categorical_accuracy: 0.9961 - output_8_sparse_categorical_accuracy: 0.8880 - output_9_sparse_categorical_accuracy: 0.9974 - output_10_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0314 - output_1_loss: 0.8881 - output_2_loss: 0.1131 - output_3_loss: 0.1779 - output_4_loss: 0.4118 - output_5_loss: 0.0544 - output_6_loss: 0.1712 - output_7_loss: 0.0265 - output_8_loss: 0.2847 - output_9_loss: 0.0200 - output_10_loss: 0.0296 - output_2_sparse_categorical_accuracy: 0.9674 - output_3_sparse_categorical_accuracy: 0.9440 - output_4_sparse_categorical_accuracy: 0.8516 - output_5_sparse_categorical_accuracy: 0.9870 - output_6_sparse_categorical_accuracy: 0.9531 - output_7_sparse_categorical_accuracy: 0.9987 - output_8_sparse_categorical_accuracy: 0.8867 - output_9_sparse_categorical_accuracy: 0.9987 - output_10_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0207 - output_1_loss: 0.8826 - output_2_loss: 0.1045 - output_3_loss: 0.1696 - output_4_loss: 0.4071 - output_5_loss: 0.0502 - output_6_loss: 0.1621 - output_7_loss: 0.0255 - output_8_loss: 0.2787 - output_9_loss: 0.0188 - output_10_loss: 0.0265 - output_2_sparse_categorical_accuracy: 0.9792 - output_3_sparse_categorical_accuracy: 0.9531 - output_4_sparse_categorical_accuracy: 0.8581 - output_5_sparse_categorical_accuracy: 0.9922 - output_6_sparse_categorical_accuracy: 0.9583 - output_7_sparse_categorical_accuracy: 0.9961 - output_8_sparse_categorical_accuracy: 0.8971 - output_9_sparse_categorical_accuracy: 0.9974 - output_10_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0066 - output_1_loss: 0.8751 - output_2_loss: 0.1001 - output_3_loss: 0.1578 - output_4_loss: 0.3981 - output_5_loss: 0.0440 - output_6_loss: 0.1518 - output_7_loss: 0.0248 - output_8_loss: 0.2658 - output_9_loss: 0.0163 - output_10_loss: 0.0255 - output_2_sparse_categorical_accuracy: 0.9792 - output_3_sparse_categorical_accuracy: 0.9570 - output_4_sparse_categorical_accuracy: 0.8529 - output_5_sparse_categorical_accuracy: 0.9935 - output_6_sparse_categorical_accuracy: 0.9622 - output_7_sparse_categorical_accuracy: 0.9974 - output_8_sparse_categorical_accuracy: 0.9062 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0043 - output_1_loss: 0.8794 - output_2_loss: 0.0983 - output_3_loss: 0.1488 - output_4_loss: 0.3761 - output_5_loss: 0.0442 - output_6_loss: 0.1429 - output_7_loss: 0.0224 - output_8_loss: 0.2531 - output_9_loss: 0.0153 - output_10_loss: 0.0235 - output_2_sparse_categorical_accuracy: 0.9792 - output_3_sparse_categorical_accuracy: 0.9518 - output_4_sparse_categorical_accuracy: 0.8672 - output_5_sparse_categorical_accuracy: 0.9909 - output_6_sparse_categorical_accuracy: 0.9583 - output_7_sparse_categorical_accuracy: 0.9961 - output_8_sparse_categorical_accuracy: 0.9062 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9972 - output_1_loss: 0.8792 - output_2_loss: 0.0913 - output_3_loss: 0.1346 - output_4_loss: 0.3577 - output_5_loss: 0.0396 - output_6_loss: 0.1338 - output_7_loss: 0.0235 - output_8_loss: 0.2445 - output_9_loss: 0.0136 - output_10_loss: 0.0234 - output_2_sparse_categorical_accuracy: 0.9792 - output_3_sparse_categorical_accuracy: 0.9766 - output_4_sparse_categorical_accuracy: 0.8815 - output_5_sparse_categorical_accuracy: 0.9948 - output_6_sparse_categorical_accuracy: 0.9674 - output_7_sparse_categorical_accuracy: 0.9987 - output_8_sparse_categorical_accuracy: 0.9141 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9950 - output_1_loss: 0.8817 - output_2_loss: 0.0877 - output_3_loss: 0.1270 - output_4_loss: 0.3518 - output_5_loss: 0.0377 - output_6_loss: 0.1252 - output_7_loss: 0.0247 - output_8_loss: 0.2311 - output_9_loss: 0.0133 - output_10_loss: 0.0218 - output_2_sparse_categorical_accuracy: 0.9857 - output_3_sparse_categorical_accuracy: 0.9714 - output_4_sparse_categorical_accuracy: 0.8724 - output_5_sparse_categorical_accuracy: 0.9948 - output_6_sparse_categorical_accuracy: 0.9674 - output_7_sparse_categorical_accuracy: 0.9948 - output_8_sparse_categorical_accuracy: 0.9284 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9936 - output_1_loss: 0.8875 - output_2_loss: 0.0813 - output_3_loss: 0.1172 - output_4_loss: 0.3292 - output_5_loss: 0.0356 - output_6_loss: 0.1181 - output_7_loss: 0.0227 - output_8_loss: 0.2168 - output_9_loss: 0.0119 - output_10_loss: 0.0221 - output_2_sparse_categorical_accuracy: 0.9831 - output_3_sparse_categorical_accuracy: 0.9779 - output_4_sparse_categorical_accuracy: 0.8971 - output_5_sparse_categorical_accuracy: 0.9948 - output_6_sparse_categorical_accuracy: 0.9701 - output_7_sparse_categorical_accuracy: 0.9987 - output_8_sparse_categorical_accuracy: 0.9206 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9853 - output_1_loss: 0.8823 - output_2_loss: 0.0784 - output_3_loss: 0.1084 - output_4_loss: 0.3227 - output_5_loss: 0.0318 - output_6_loss: 0.1110 - output_7_loss: 0.0214 - output_8_loss: 0.2210 - output_9_loss: 0.0117 - output_10_loss: 0.0212 - output_2_sparse_categorical_accuracy: 0.9870 - output_3_sparse_categorical_accuracy: 0.9779 - output_4_sparse_categorical_accuracy: 0.8971 - output_5_sparse_categorical_accuracy: 0.9974 - output_6_sparse_categorical_accuracy: 0.9753 - output_7_sparse_categorical_accuracy: 0.9935 - output_8_sparse_categorical_accuracy: 0.9284 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9765 - output_1_loss: 0.8792 - output_2_loss: 0.0749 - output_3_loss: 0.0999 - output_4_loss: 0.3063 - output_5_loss: 0.0296 - output_6_loss: 0.1118 - output_7_loss: 0.0212 - output_8_loss: 0.2042 - output_9_loss: 0.0105 - output_10_loss: 0.0170 - output_2_sparse_categorical_accuracy: 0.9883 - output_3_sparse_categorical_accuracy: 0.9857 - output_4_sparse_categorical_accuracy: 0.8984 - output_5_sparse_categorical_accuracy: 0.9948 - output_6_sparse_categorical_accuracy: 0.9792 - output_7_sparse_categorical_accuracy: 0.9935 - output_8_sparse_categorical_accuracy: 0.9362 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9798 - output_1_loss: 0.8871 - output_2_loss: 0.0684 - output_3_loss: 0.0923 - output_4_loss: 0.2961 - output_5_loss: 0.0290 - output_6_loss: 0.1137 - output_7_loss: 0.0213 - output_8_loss: 0.1862 - output_9_loss: 0.0103 - output_10_loss: 0.0165 - output_2_sparse_categorical_accuracy: 0.9896 - output_3_sparse_categorical_accuracy: 0.9805 - output_4_sparse_categorical_accuracy: 0.9193 - output_5_sparse_categorical_accuracy: 0.9974 - output_6_sparse_categorical_accuracy: 0.9701 - output_7_sparse_categorical_accuracy: 0.9974 - output_8_sparse_categorical_accuracy: 0.9440 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9664 - output_1_loss: 0.8790 - output_2_loss: 0.0676 - output_3_loss: 0.0841 - output_4_loss: 0.2852 - output_5_loss: 0.0267 - output_6_loss: 0.1051 - output_7_loss: 0.0192 - output_8_loss: 0.1735 - output_9_loss: 0.0097 - output_10_loss: 0.0148 - output_2_sparse_categorical_accuracy: 0.9922 - output_3_sparse_categorical_accuracy: 0.9909 - output_4_sparse_categorical_accuracy: 0.9036 - output_5_sparse_categorical_accuracy: 0.9987 - output_6_sparse_categorical_accuracy: 0.9753 - output_7_sparse_categorical_accuracy: 0.9948 - output_8_sparse_categorical_accuracy: 0.9466 - output_9_sparse_categorical_accuracy: 1.0000 - output_10_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9595 - output_1_loss: 0.8772 - output_2_loss: 0.0634 - output_3_loss: 0.0800 - output_4_loss: 0.2708 - output_5_loss: 0.0252 - output_6_loss: 0.0948 - output_7_loss: 0.0178 - output_8_loss: 0.1683 - output_9_loss: 0.0090 - output_10_loss: 0.0117 - output_2_sparse_categorical_accuracy: 0.9896 - output_3_sparse_categorical_accuracy: 0.9844 - output_4_sparse_categorical_accuracy: 0.9323 - output_5_sparse_categorical_accuracy: 0.9987 - output_6_sparse_categorical_accuracy: 0.9805 - output_7_sparse_categorical_accuracy: 0.9987 - output_8_sparse_categorical_accuracy: 0.9505 - output_9_sparse_categorical_accuracy: 0.9987 - output_10_sparse_categorical_accuracy: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d0aa00910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编译模型\n",
    "heae.compile(optimizer=optimizer,\n",
    "             loss=he_loss,\n",
    "             loss_weights=he_loss_weights,\n",
    "             metrics=metrics)\n",
    "\n",
    "# 定义训练数据集\n",
    "# 注意：您需要确保您的数据已经经过了适当的预处理\n",
    "# 使用整个数据集重新训练LabelEncoder\n",
    "for column in categorical_features:\n",
    "    label_encoders[column].fit(X_train[column])\n",
    "\n",
    "\n",
    "# 然后，您可以继续使用heae_preprocessor函数进行预处理\n",
    "\n",
    "trainset_input = heae_preprocessor(X_train).astype(np.float32)\n",
    "trainset_outputs = {\n",
    "    \"output_1\": trainset_input.iloc[:, :len(numerical_features)]\n",
    "\n",
    "}\n",
    "\n",
    "for i, cat_id in enumerate(categorical_features):\n",
    "    trainset_outputs.update({\n",
    "        f\"output_{i+2}\": X_train.loc[:, cat_id]\n",
    "    })\n",
    "\n",
    "trainset = tf.data.Dataset.from_tensor_slices((trainset_input, trainset_outputs))\n",
    "trainset = trainset.shuffle(1024).batch(128, drop_remainder=True)\n",
    "\n",
    "# 训练模型\n",
    "heae.fit(trainset, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeeb1c5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m target_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 生成反事实\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Print the counterfactual\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal instance:\u001b[39m\u001b[38;5;124m\"\u001b[39m, instance)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\cfrl_tabular.py:341\u001b[0m, in \u001b[0;36mCounterfactualRLTabular.explain\u001b[1;34m(self, X, Y_t, C, batch_size, diversity, num_samples, patience, tolerance)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Get conditioning for a zero input. Used for a sanity check of the user-specified conditioning.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m X_zeros \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m--> 341\u001b[0m C_zeros \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconditional_func\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_zeros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# If the conditional vector is `None`. This is equivalent of no conditioning at all, not even during training.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m C \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;66;03m# Check if the conditional function actually a `None` conditioning\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\backends\\cfrl_tabular.py:275\u001b[0m, in \u001b[0;36mgenerate_condition\u001b[1;34m(X_ohe, feature_names, category_map, ranges, immutable_features, conditional)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# Generate categorical condition vector.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(category_map):\n\u001b[1;32m--> 275\u001b[0m     C_cat \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_categorical_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ohe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_ohe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcategory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mimmutable_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimmutable_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mconditional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconditional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     C\u001b[38;5;241m.\u001b[39mappend(C_cat)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# Concatenate numerical and categorical conditional vectors.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\alibi\\explainers\\backends\\cfrl_tabular.py:222\u001b[0m, in \u001b[0;36mgenerate_categorical_condition\u001b[1;34m(X_ohe, feature_names, category_map, immutable_features, conditional)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# Move to the next categorical index\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     cat_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "encoder = CreditEncoder(hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM)\n",
    "decoder = CreditDecoder(hidden_dim=HIDDEN_DIM, output_dims=OUTPUT_DIMS)\n",
    "\n",
    "category_map = {feature: list(X[feature].unique()) for feature in categorical_features}\n",
    "\n",
    "class XGBoostWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, instances):\n",
    "        return self.model.predict_proba(instances)\n",
    "\n",
    "# Wrap the XGBoost model\n",
    "wrapped_model = XGBoostWrapper(clf_xgb)\n",
    "\n",
    "# 3. Initialize the Counterfactual Generator\n",
    "cf = CounterfactualRLTabular(\n",
    "    predictor=wrapped_model.predict,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    encoder_preprocessor=heae_preprocessor,\n",
    "    decoder_inv_preprocessor=credit_inv_preprocessor,\n",
    "    coeff_sparsity=0.5,\n",
    "    coeff_consistency=0.5,\n",
    "    feature_names=list(X.columns),\n",
    "    category_map=category_map,\n",
    "    immutable_features=immutable_features,\n",
    "    ranges=None,  # You can define the ranges as described in the documentation if needed\n",
    "    weight_num=1.0,\n",
    "    weight_cat=1.0,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    backend='tensorflow',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "# 4. Generate Counterfactuals\n",
    "# For demonstration, let's take the first instance from the test set\n",
    "instance = X_test_scaled[0].reshape(1, -1)\n",
    "# 假设你的目标类别是0\n",
    "target_class = np.array([[0]])\n",
    "\n",
    "# 生成反事实\n",
    "explanation = cf.explain(instance, Y_t=target_class)\n",
    "\n",
    "# Print the counterfactual\n",
    "print(\"Original instance:\", instance)\n",
    "print(\"Counterfactual instance:\", explanation.cf['X'])\n",
    "\n",
    "# encoder = CreditEncoder(hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM)\n",
    "# decoder = CreditDecoder(hidden_dim=HIDDEN_DIM, output_dims=OUTPUT_DIMS)\n",
    "\n",
    "# category_map = {feature: list(X[feature].unique()) for feature in categorical_features}\n",
    "\n",
    "# class XGBoostWrapper:\n",
    "#     def __init__(self, model):\n",
    "#         self.model = model\n",
    "\n",
    "#     def predict(self, instances):\n",
    "#         return self.model.predict_proba(instances)\n",
    "\n",
    "# # Wrap the XGBoost model\n",
    "# wrapped_model = XGBoostWrapper(clf_xgb)\n",
    "\n",
    "# # 3. Initialize the Counterfactual Generator\n",
    "# cf = CounterfactualRLTabular(\n",
    "#     ohe = False,\n",
    "#     predictor=wrapped_model.predict,\n",
    "#     encoder=encoder,\n",
    "#     decoder=decoder,\n",
    "#     encoder_preprocessor=heae_preprocessor,\n",
    "#     decoder_inv_preprocessor=credit_inv_preprocessor,\n",
    "#     coeff_sparsity=0.5,\n",
    "#     coeff_consistency=0.5,\n",
    "#     category_map=category_map,\n",
    "#     data=X_train_scaled,\n",
    "#     categorical_features=categorical_features,\n",
    "#     continuous_features=continuous_features,\n",
    "#     immutable_features=immutable_features,\n",
    "#     non_decreasing_features=non_decreasing_features,\n",
    "#     correlated_features=correlated_features,\n",
    "#     feature_names=list(X.columns),\n",
    "#     outcome_name='target',\n",
    "#     task='classification',\n",
    "#     max_counterfactual_length=5,\n",
    "#     counterfactual_feature_range=None,\n",
    "#     counterfactual_target_range=None,\n",
    "#     reward_func=None,\n",
    "#     reward_type='l2',\n",
    "#     lam=0.1,\n",
    "#     learning_rate=1e-3,\n",
    "#     latent_dim = LATENT_DIM,\n",
    "#     max_iterations=5000,\n",
    "#     batch_size=100,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# # 4. Generate Counterfactuals\n",
    "# # For demonstration, let's take the first instance from the test set\n",
    "# instance = X_test_scaled[0].reshape(1, -1)\n",
    "# # 假设你的目标类别是1\n",
    "# target_class = np.array([[0]])\n",
    "\n",
    "# # 生成反事实\n",
    "# explanation = cf.explain(instance, Y_t=target_class)\n",
    "\n",
    "\n",
    "# # Print the counterfactual\n",
    "# print(\"Original instance:\", instance)\n",
    "# print(\"Counterfactual instance:\", explanation.cf['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8b944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
